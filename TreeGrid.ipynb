{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e10e761c-fced-4d0c-b50d-c51137da3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ad1f51d-a451-4220-bf91-a07228e9f5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset = TreeGridDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6139d41-43d9-47fc-8cc9-e187e65a2fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1231"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].ndata['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d682e452-d3ae-4c61-ba5c-4dc091a94a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([1,3,6,5,9,2],int(10*0.21),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b01836a-a898-48c1-b192-6a3c6f85c065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([6,1,3] )\n",
    "b = np.array([3,1])\n",
    "[x for x in a if x not in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "694cfa42-d017-4b8d-b5e2-0a8c108c5b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcb059de-e187-41be-8388-67dfb065a191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data from cached files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_165394/96704680.py:32: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  train = df[df['name'].str.contains(re.compile(train_pattern))]\n",
      "/tmp/ipykernel_165394/96704680.py:38: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  val = df[df['name'].str.contains(re.compile(val_pattern))]\n",
      "/tmp/ipykernel_165394/96704680.py:44: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  test = df[df['name'].str.contains(re.compile(test_pattern))]\n"
     ]
    }
   ],
   "source": [
    "arg = TreeGridDataset\n",
    "# this is an example of disjoint label multiple graphs.\n",
    "dataset_name = arg.__name__\n",
    "dataset = arg()\n",
    "\n",
    "# assume you have a list of DGL graphs stored in the variable dgl_Gs\n",
    "if len(dataset) == 1:\n",
    "    dgl_Gs = [dataset[0]]\n",
    "else:\n",
    "    dgl_Gs = list(dataset)\n",
    "# assume you have an array of features where [feat_1, feat_2, ...] and each feat_i corresponding to the graph i.\n",
    "feature_map = [np.array(graph.ndata['feat']) for graph in dgl_Gs]\n",
    "# assume you have an array of labels where [label_1, label_2, ...] and each label_i corresponding to the graph i.\n",
    "label_map = [np.array(graph.ndata['label']) for graph in dgl_Gs]\n",
    "\n",
    "info = {}\n",
    "\n",
    "for idx, G in enumerate(dgl_Gs):    \n",
    "    # G is a dgl graph\n",
    "    for j in range(len(label_map[idx])):\n",
    "        info[str(idx) + '_' + str(j)] = label_map[idx][j]\n",
    "            \n",
    "df = pd.DataFrame.from_dict(info, orient='index').reset_index().rename(columns={\"index\": \"name\", 0: \"label\"})\n",
    "\n",
    "train_df_list = []\n",
    "val_df_list = []\n",
    "test_df_list = []\n",
    "for idx, G in enumerate(dgl_Gs):\n",
    "    num_labels = list(range(len(G.ndata['label'])))\n",
    "    train_ind = np.random.choice(num_labels,int(len(num_labels)*0.7),replace=False)\n",
    "    train_pattern = str(idx)+'_(' + '|'.join(map(str, train_ind)) + ')$'\n",
    "    train = df[df['name'].str.contains(re.compile(train_pattern))]\n",
    "    train_df_list.append(train)\n",
    "    num_labels = [x for x in num_labels if x not in train_ind]\n",
    "    \n",
    "    val_ind = np.random.choice(num_labels,int(len(num_labels)*0.33),replace=False)\n",
    "    val_pattern = str(idx)+'_(' + '|'.join(map(str, val_ind)) + ')$'\n",
    "    val = df[df['name'].str.contains(re.compile(val_pattern))]\n",
    "    val_df_list.append(val)\n",
    "    num_labels = [x for x in num_labels if x not in val_ind]\n",
    "    \n",
    "    test_ind = num_labels\n",
    "    test_pattern = str(idx)+'_(' + '|'.join(map(str, test_ind)) + ')$'\n",
    "    test = df[df['name'].str.contains(re.compile(test_pattern))]\n",
    "    test_df_list.append(test)\n",
    "    \n",
    "train_df = pd.concat(train_df_list)\n",
    "val_df = pd.concat(val_df_list)\n",
    "test_df = pd.concat(test_df_list)\n",
    "\n",
    "directory = Path('data/' + str(dataset_name))\n",
    "if not directory.exists():\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_df.reset_index(drop = True).to_csv('data/' + str(dataset_name) + '/train.csv')\n",
    "val_df.reset_index(drop = True).to_csv('data/' + str(dataset_name) + '/val.csv')\n",
    "test_df.reset_index(drop = True).to_csv('data/' + str(dataset_name) + '/test.csv')\n",
    "\n",
    "with open('data/' + str(dataset_name) + '/graph_dgl.pkl', 'wb') as f:\n",
    "    pickle.dump(dgl_Gs, f)\n",
    "    \n",
    "with open('data/' + str(dataset_name) + '/label.pkl', 'wb') as f:\n",
    "    pickle.dump(info, f)\n",
    "    \n",
    "np.save('data/' + str(dataset_name) + '/features.npy', np.array(feature_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627800c-d777-4362-842e-4dc9bfa3bdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epoch=10, n_way=3, k_spt=3, k_qry=5, task_num=8, meta_lr=0.001, update_lr=0.001, update_step=5, update_step_test=10, input_dim=1, hidden_dim=64, attention_size=32, data_dir='data/TreeGridDataset/', no_finetune=True, task_setup='Shared', method='G-Meta', task_n=1, task_mode='False', val_result_report_steps=100, train_result_report_steps=100, num_workers=0, batchsz=1000, link_pred_mode='False', h=2, sample_nodes=1000)\n",
      "There are 2 classes \n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 1x64 (cuda:0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 64 (cuda:0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 64x64 (cuda:0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 64 (cuda:0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 2x64 (cuda:0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 2 (cuda:0)]\n",
      "    )\n",
      "    (_manifold): PoincareBall manifold\n",
      "  )\n",
      "  (_manifold): PoincareBall manifold\n",
      ")\n",
      "Total trainable tensors: 4418\n",
      "shuffle DB :train, b:1000, 3-way, 3-shot, 5-query, 2-hops\n",
      "shuffle DB :val, b:100, 3-way, 3-shot, 5-query, 2-hops\n",
      "shuffle DB :test, b:100, 3-way, 3-shot, 5-query, 2-hops\n",
      "------ Start Training ------\n",
      "Epoch: 1  Step: 0  training acc: 0.475  time elapsed: 97.42  data loading takes: 1.664  Memory usage: 190.2\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data_dir data/TreeGridDataset/ --task_setup Shared --train_result_report_steps 100 --k_qry 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf5c87-c27b-4f1b-923e-4c5a1f5ea4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data_dir data/TreeGridDataset/ --task_setup Shared --train_result_report_steps 100 --k_qry 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f10e0-9f4e-4f98-992d-5c776873f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data_dir data/TreeGridDataset/ --task_setup Shared --train_result_report_steps 100 --k_qry 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1162242-6ec2-418b-99db-f7084424808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data_dir data/TreeGridDataset/ --task_setup Shared --train_result_report_steps 100 --k_qry 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5520819-9400-422f-b084-15b23965ebdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
